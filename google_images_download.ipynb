{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting you a lot of images. This may take a few moments...\n",
      "Reached end of page.\n",
      "Retry\n",
      "\n",
      "\n",
      "Download completed. [Successful count = 707].\n",
      "Total time is 457.2073857784271 seconds.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import urllib3\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "searchword1 = 'army'\n",
    "searchword2 = 'truck'\n",
    "searchword3 = 'vehicle'\n",
    "searchurl = 'https://www.google.com/search?q=' + searchword1 + '+' + searchword2 + '+' + searchword3 + '&source=lnms&tbm=isch'\n",
    "dirs = 'pictures' \n",
    "maxcount = 1000\n",
    "\n",
    "chromedriver = 'C://Program Files//chromedriver//chromedriver.exe'\n",
    "\n",
    "if not os.path.exists(dirs):\n",
    "    os.mkdir(dirs)\n",
    "\n",
    "def download_google_staticimages():\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    #options.add_argument('--headless')\n",
    "\n",
    "    try:\n",
    "        browser = webdriver.Chrome(chromedriver, options=options)\n",
    "    except Exception as e:\n",
    "        print(f'No found chromedriver in this environment.')\n",
    "        print(f'Install on your machine. exception: {e}')\n",
    "        sys.exit()\n",
    "\n",
    "    browser.set_window_size(1280, 1024)\n",
    "    browser.get(searchurl)\n",
    "    time.sleep(1)\n",
    "\n",
    "    print(f'Getting you a lot of images. This may take a few moments...')\n",
    "\n",
    "    element = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    # Scroll down\n",
    "    #for i in range(30):\n",
    "    for i in range(50):\n",
    "        element.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    try:\n",
    "        browser.find_element_by_id('smb').click()\n",
    "        for i in range(50):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "    except:\n",
    "        for i in range(10):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    print(f'Reached end of page.')\n",
    "    time.sleep(0.5)\n",
    "    print(f'Retry')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Below is in japanese \"show more result\" sentences. Change this word to your lanaguage if you require.\n",
    "    browser.find_element_by_xpath('//input[@value=\"Show more results\"]').click()\n",
    "\n",
    "    # Scroll down 2\n",
    "    for i in range(50):\n",
    "        element.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    try:\n",
    "        browser.find_element_by_id('smb').click()\n",
    "        for i in range(50):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "    except:\n",
    "        for i in range(10):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    #elements = browser.find_elements_by_xpath('//div[@id=\"islrg\"]')\n",
    "    #page_source = elements[0].get_attribute('innerHTML')\n",
    "    page_source = browser.page_source \n",
    "\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    images = soup.find_all('img')\n",
    "\n",
    "    urls = []\n",
    "    for image in images:\n",
    "        try:\n",
    "            url = image['data-src']\n",
    "            if not url.find('https://'):\n",
    "                urls.append(url)\n",
    "        except:\n",
    "            try:\n",
    "                url = image['src']\n",
    "                if not url.find('https://'):\n",
    "                    urls.append(image['src'])\n",
    "            except Exception as e:\n",
    "                print(f'No found image sources.')\n",
    "                print(e)\n",
    "\n",
    "    count = 0\n",
    "    if urls:\n",
    "        for url in urls:\n",
    "            try:\n",
    "                res = requests.get(url, verify=False, stream=True)\n",
    "                rawdata = res.raw.read()\n",
    "                with open(os.path.join(dirs, 'img_' + str(count) + '.jpg'), 'wb') as f:\n",
    "                    f.write(rawdata)\n",
    "                    count += 1\n",
    "            except Exception as e:\n",
    "                print('Failed to write rawdata.')\n",
    "                print(e)\n",
    "\n",
    "    browser.close()\n",
    "    return count\n",
    "\n",
    "# Main block\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    count = download_google_staticimages()\n",
    "    t1 = time.time()\n",
    "\n",
    "    total_time = t1 - t0\n",
    "    print(f'\\n')\n",
    "    print(f'Download completed. [Successful count = {count}].')\n",
    "    print(f'Total time is {str(total_time)} seconds.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
